{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid',context='notebook')\n",
    "cols=['LSTAT','INDUS','NOX','RM','MEDV']\n",
    "sns.pairplot(df[cols],height=2.5);\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "x=df[['RM']].values #x axis\n",
    "y=df['MEDV'].values# y axis\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid',context='notebook')\n",
    "sns.pairplot(df[cols],height=2.5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x,model.predict(x),color='red',line_width=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(C=1000.0,random_state=0)\n",
    "lr.fit(x_train_std,y_train)\n",
    "#y_train is the class label\n",
    "a=lr.predict_proba(x_test_std[0, :].reshape(1,-1))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "ppn = Perceptron(max_iter=40, eta0=0.1, random_state=0)\n",
    "ppn.fit(x_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XOR implementation in TensorFlow with linear activation for hidden layers\n",
    "import tensorflow as tf\n",
    "#create placeholders for training input and output labels\n",
    "x_=tf.placeholder(tf.float32,shape=[4,2],name=\"x_input\")\n",
    "y_=tf.placeholder(tf.float32,shape=[4,1],name=\"y_input\")\n",
    "#define the weights to the hidden and output layer respectively\n",
    "w1=tf.Variable(tf.random_uniform([2,2], -1, 1),name=\"Weights1\")\n",
    "w2=tf.Variable(tf.random_uniform([2,2], -1, 1),name=\"Weihjts2\")\n",
    "#define the bias to the hidden and outer layer respectively\n",
    "b1=tf.Variable(tf.zeros([2]),name=\"Bias1\")\n",
    "b2=tf.Variable(tf.zeros([1]),name=\"Bias2\")\n",
    "#define the final output through forward pass\n",
    "z2=tf.matmul(x_,w1)+b1 #linear activation function in hdden layer\n",
    "pred=tf.sigmoid(tf.matmul(z2,w2)+b2) #non linear activation function in output layer\n",
    "#define the cross-entropy/log-loss cost function based on the output probability by the forward pass\n",
    "cost=tf.reduce_mean(((y_*tf.log(pred))+((1-y_)*tf.log(1.0-pred)))*-1)\n",
    "learning_rate=0.01\n",
    "train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "#now we will start the training \n",
    "XOR_X=[[0,0],[0,1],[1,0],[1,1]]\n",
    "XOR_Y=[[0],[1],[1],[0]]\n",
    "init=tf.initialize_all_variables()\n",
    "sess=tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(100000):\n",
    "    sess.run(train_step,feed_dict={x_:XOR_X,y_:XOR_Y})\n",
    "    if i%10000==0:\n",
    "        print('Epoch ',i)\n",
    "        print('prediction:',sess.run(pred,feed_dict={x_:XOR_X,y_:XOR_Y}))\n",
    "        print('Weights fom input to hidden layer:',sess.run(w1))\n",
    "        print('Bias in the hidden layer:',sess.run(b1))\n",
    "        print('Weights from hidden layer to output layer:',sess.run(w2))\n",
    "        print('Bias in the output layer:',sess.run(b2))\n",
    "        print('Cost:',sess.run(cost,feed_dict={x_:XOR_X,y_:XOR_Y}))\n",
    "print('Final prediction',sess.run(pred,feed_dict={x_:XOR_X,y_:XOR_Y}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
    "dtree.fit(x_train, y_train)# use the model to make predictions with the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf=svm.SVC(kernel='linear')\n",
    "clf.fit(x_train,y_train)\n",
    "y_pred=clf.predict(x_test)\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy \",metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf=DecisionTreeClassifier(max_depth=5,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf=MLPClassifier(max_iter=500,random_state=0,alpha=0.001,hidden_layer_sizes=(100,),activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh=KNeighborsClassifier(n_neighbors=num)\n",
    "    neigh.fit(x_train,y_train)\n",
    "    y_pred=neigh.predict(x_test)\n",
    "    acc_score=accuracy_score(y_test,y_pred)\n",
    "    return acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "#OVER SAMPLING THE DATA\n",
    "sm=SMOTE(random_state=0)\n",
    "X_res,y_res=sm.fit_resample(X,y)\n",
    "print('Resampled data shape %s' % Counter(y_res))\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "cc = ClusterCentroids(random_state=0)\n",
    "X_res, y_res = cc.fit_resample(X, y)\n",
    "print('Resampled data shape %s' %Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=pd.merge(movies,ratings,on='movieId')\n",
    "mat=d1.pivot(\n",
    "index='movieId',\n",
    "columns='userId',\n",
    "values='rating').fillna(0)\n",
    "from sklearn.cluster import KMeans\n",
    "km=KMeans(n_clusters=10)\n",
    "km.fit(mat)\n",
    "labels=km.labels_\n",
    "print(labels)\n",
    "def clusterindexnumpy(clustnum,label):\n",
    "     return np.where(clustnum==label)[0]\n",
    "a=clusterindexnumpy(3,labels)\n",
    "print(a)\n",
    "d3=([movies.loc[movies['movieId']==a1] for a1 in a])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
